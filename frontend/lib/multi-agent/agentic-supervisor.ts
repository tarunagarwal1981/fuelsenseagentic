/**
 * Agentic Supervisor - ReAct Pattern Implementation
 * 
 * Implements a truly agentic supervisor that uses continuous LLM reasoning
 * to adaptively route between agents, handle failures, and make intelligent decisions.
 * 
 * ReAct Loop:
 * 1. REASON: LLM thinks about current state
 * 2. ACT: Execute the chosen action
 * 3. OBSERVE: Update state with results
 * 4. DECIDE: Continue or finish?
 * 
 * Agency Breakdown:
 * - Intent Understanding: 15% (LLM deep reasoning)
 * - Adaptive Routing: 20% (LLM decides agent order dynamically)
 * - Error Recovery: 15% (LLM proposes recovery strategies)
 * - Prerequisite Flexibility: 10% (LLM understands when rules can bend)
 * - Clarification Handling: 10% (LLM asks intelligent questions)
 * - Multi-turn Memory: 5% (Reasoning history maintained)
 * Total Agentic: 75%
 * Deterministic (math, APIs): 25%
 */

import { HumanMessage, SystemMessage } from '@langchain/core/messages';
import { LLMFactory } from './llm-factory';
import { AgentRegistry } from './registry';
import type { MultiAgentState, ReasoningStep } from './state';

// ============================================================================
// Constants
// ============================================================================

const MAX_REASONING_STEPS = 15;
const MAX_RECOVERY_ATTEMPTS = 3;

// ============================================================================
// Types
// ============================================================================

interface Reasoning {
  thought: string;
  action: 'call_agent' | 'validate' | 'recover' | 'clarify' | 'finalize';
  params?: {
    agent?: string;
    recovery_action?: 'retry_agent' | 'skip_agent' | 'ask_user';
    question?: string;
    [key: string]: unknown;
  };
}

// ============================================================================
// Main Reasoning Supervisor
// ============================================================================

/**
 * Agentic Reasoning Supervisor
 * 
 * Uses ReAct pattern to make intelligent routing decisions.
 * Replaces hard-coded if/else routing with LLM-powered reasoning.
 */
export async function reasoningSupervisor(
  state: MultiAgentState
): Promise<Partial<MultiAgentState>> {
  console.log('\nüß† [AGENTIC-SUPERVISOR] Starting reasoning loop...');
  
  // Check limits
  const reasoningStepCount = state.reasoning_history?.length || 0;
  if (reasoningStepCount >= MAX_REASONING_STEPS) {
    console.warn('‚ö†Ô∏è [AGENTIC-SUPERVISOR] Max reasoning steps reached');
    return {
      next_agent: 'finalize',
      current_thought: 'Maximum reasoning steps reached, finalizing with available data',
      needs_clarification: false,
    };
  }
  
  const recoveryAttempts = state.recovery_attempts || 0;
  if (recoveryAttempts >= MAX_RECOVERY_ATTEMPTS) {
    console.warn('‚ö†Ô∏è [AGENTIC-SUPERVISOR] Max recovery attempts reached');
    return {
      next_agent: 'finalize',
      needs_clarification: true,
      clarification_question: 'I encountered multiple issues processing your request. Could you please rephrase or provide more specific details?',
      current_thought: 'Unable to recover from errors after multiple attempts, need user input',
    };
  }
  
  // Generate reasoning
  const reasoning = await generateReasoning(state);
  
  // Log reasoning
  console.log('üí≠ [AGENTIC-SUPERVISOR] Thought:', reasoning.thought.substring(0, 200));
  console.log('üéØ [AGENTIC-SUPERVISOR] Action:', reasoning.action);
  if (reasoning.params?.agent) {
    console.log('üìç [AGENTIC-SUPERVISOR] Target agent:', reasoning.params.agent);
  }
  
  // Record reasoning step
  const step: ReasoningStep = {
    step_number: reasoningStepCount + 1,
    thought: reasoning.thought,
    action: reasoning.action,
    action_params: reasoning.params,
    timestamp: new Date(),
  };
  
  // Execute action
  return executeReasoningAction(reasoning, state, step);
}

// ============================================================================
// Reasoning Generation
// ============================================================================

/**
 * Generate reasoning using LLM
 * 
 * Analyzes current state and decides what to do next.
 */
async function generateReasoning(state: MultiAgentState): Promise<Reasoning> {
  const llm = LLMFactory.getLLMForTask('reasoning');
  
  const systemPrompt = buildSystemPrompt();
  const userPrompt = buildReasoningPrompt(state);
  
  const response = await llm.invoke([
    new SystemMessage(systemPrompt),
    new HumanMessage(userPrompt),
  ]);
  
  // Parse JSON response
  const content = typeof response.content === 'string' 
    ? response.content 
    : JSON.stringify(response.content);
  
  const jsonMatch = content.match(/\{[\s\S]*\}/);
  if (!jsonMatch) {
    console.error('‚ùå [AGENTIC-SUPERVISOR] Failed to parse reasoning response');
    // Fallback to safe default
    return {
      thought: 'Unable to parse reasoning, defaulting to finalize',
      action: 'finalize',
      params: {},
    };
  }
  
  try {
    return JSON.parse(jsonMatch[0]);
  } catch (error) {
    console.error('‚ùå [AGENTIC-SUPERVISOR] JSON parse error:', error);
    return {
      thought: 'JSON parse failed, defaulting to finalize',
      action: 'finalize',
      params: {},
    };
  }
}

/**
 * Build system prompt for reasoning
 */
function buildSystemPrompt(): string {
  const agentDescriptions = getAgentDescriptions();
  
  return `You are an intelligent maritime operations coordinator.
Your job is to reason through complex queries and decide what to do next.

AVAILABLE AGENTS:
${agentDescriptions}

REASONING FRAMEWORK:
1. Understand what the user is really asking for
2. Analyze what data we have vs what we need
3. Consider prerequisites and dependencies
4. Handle failures gracefully with alternative approaches
5. Ask for clarification when truly ambiguous

IMPORTANT PRINCIPLES:
- NOT ALL queries need ALL agents (be smart!)
- Port weather ‚â† Route weather (different requirements)
- If an agent fails, consider why and adapt
- Sometimes partial answers are better than no answer
- Ask users for help when stuck (don't guess)
- NEVER route to an agent that has already failed unless trying recovery

ACTIONS YOU CAN TAKE:
1. "call_agent" - Route to a specific agent. Params: { "agent": "route_agent" | "weather_agent" | "bunker_agent" | "compliance_agent" }
2. "validate" - Validate prerequisites before proceeding. Params: { "check": "description" }
3. "recover" - Attempt error recovery. Params: { "recovery_action": "retry_agent" | "skip_agent" | "ask_user", "agent": "agent_name" }
4. "clarify" - Ask user for clarification. Params: { "question": "your question" }
5. "finalize" - Finalize and return response. Params: {}

OUTPUT FORMAT (strict JSON):
{
  "thought": "Your step-by-step reasoning about the current situation and what to do next",
  "action": "call_agent" | "validate" | "recover" | "clarify" | "finalize",
  "params": { ... }
}

CRITICAL: Always return valid JSON. The "thought" field should explain your reasoning clearly.`;
}

/**
 * Build user prompt with current state
 */
function buildReasoningPrompt(state: MultiAgentState): string {
  const userMessage = state.messages.find(msg => msg instanceof HumanMessage);
  const query = userMessage 
    ? (typeof userMessage.content === 'string' ? userMessage.content : String(userMessage.content))
    : 'Unknown query';
  
  const stateSummary = summarizeState(state);
  const agentStatus = summarizeAgentStatus(state);
  const recentReasoning = summarizeRecentReasoning(state);
  
  return `
CURRENT SITUATION:
Query: "${query}"

AVAILABLE DATA:
${stateSummary}

AGENT STATUS:
${agentStatus}

RECENT REASONING:
${recentReasoning}

TASK:
Think step-by-step about what to do next. Consider:
1. What is the user actually asking for?
2. What data do I already have?
3. What data do I still need?
4. Are there any blockers or failures?
5. Can I proceed with what I have?
6. Should I ask for clarification?

IMPORTANT CHECKS:
- If query is about port weather at a specific location (NOT a route), go directly to weather_agent
- If query needs bunker analysis but we already have route_data and weather_consumption, go to bunker_agent
- If all required data is available, go to finalize
- If an agent has failed, consider recovery options

Provide your reasoning and next action as JSON.`;
}

// ============================================================================
// State Summarization
// ============================================================================

/**
 * Summarize current state for reasoning
 */
function summarizeState(state: MultiAgentState): string {
  const items: string[] = [];
  
  if (state.route_data) {
    items.push(`‚úÖ Route: ${state.route_data.origin_port_code} ‚Üí ${state.route_data.destination_port_code} (${state.route_data.distance_nm}nm, ${state.route_data.estimated_hours}hrs)`);
  } else {
    items.push('‚ùå Route: Not calculated');
  }
  
  if (state.vessel_timeline) {
    items.push(`‚úÖ Timeline: ${state.vessel_timeline.length} waypoints`);
  } else {
    items.push('‚ùå Timeline: Not available');
  }
  
  if (state.compliance_data) {
    items.push('‚úÖ Compliance: ECA zones validated');
  } else {
    items.push('‚ùå Compliance: Not checked');
  }
  
  if (state.weather_forecast) {
    items.push(`‚úÖ Weather forecast: ${state.weather_forecast.length} points`);
  } else {
    items.push('‚ùå Weather forecast: Not retrieved');
  }
  
  if (state.weather_consumption) {
    items.push(`‚úÖ Weather-adjusted consumption: +${state.weather_consumption.consumption_increase_percent.toFixed(1)}%`);
  } else {
    items.push('‚ùå Weather-adjusted consumption: Not calculated');
  }
  
  if (state.standalone_port_weather) {
    items.push(`‚úÖ Port weather: ${state.standalone_port_weather.port_name}`);
  }
  
  if (state.bunker_ports && state.bunker_ports.length > 0) {
    items.push(`‚úÖ Bunker ports: ${state.bunker_ports.length} found`);
  } else {
    items.push('‚ùå Bunker ports: Not identified');
  }
  
  if (state.port_prices) {
    const portCount = state.port_prices.prices_by_port 
      ? Object.keys(state.port_prices.prices_by_port).length 
      : 0;
    items.push(`‚úÖ Port prices: ${portCount} ports`);
  } else {
    items.push('‚ùå Port prices: Not fetched');
  }
  
  if (state.bunker_analysis && state.bunker_analysis.recommendations?.length > 0) {
    items.push(`‚úÖ Bunker analysis: ${state.bunker_analysis.recommendations.length} options, best: ${state.bunker_analysis.best_option?.port_name}`);
  } else {
    items.push('‚ùå Bunker analysis: Not done');
  }
  
  if (state.rob_tracking) {
    items.push('‚úÖ ROB tracking: Available');
  }
  
  if (state.multi_bunker_plan?.required) {
    items.push(`‚úÖ Multi-port plan: ${state.multi_bunker_plan.plans?.length || 0} options`);
  }
  
  return items.join('\n');
}

/**
 * Summarize agent status
 */
function summarizeAgentStatus(state: MultiAgentState): string {
  const status = state.agent_status || {};
  const errors = state.agent_errors || {};
  const items: string[] = [];
  
  const allAgents = ['route_agent', 'compliance_agent', 'weather_agent', 'bunker_agent'];
  
  for (const agent of allAgents) {
    const result = status[agent];
    const error = errors[agent];
    
    if (result === 'success') {
      items.push(`‚úÖ ${agent}: SUCCESS`);
    } else if (result === 'failed') {
      items.push(`‚ùå ${agent}: FAILED${error ? ` - ${error.error}` : ''}`);
    } else if (result === 'skipped') {
      items.push(`‚è≠Ô∏è ${agent}: SKIPPED`);
    } else {
      items.push(`‚è≥ ${agent}: Not executed`);
    }
  }
  
  return items.length > 0 ? items.join('\n') : 'No agents executed yet';
}

/**
 * Summarize recent reasoning steps
 */
function summarizeRecentReasoning(state: MultiAgentState): string {
  const history = state.reasoning_history || [];
  
  if (history.length === 0) {
    return 'None yet (first reasoning step)';
  }
  
  // Show last 3 steps
  const recentSteps = history.slice(-3);
  return recentSteps.map(step => 
    `Step ${step.step_number}: ${step.thought.substring(0, 100)}... ‚Üí ${step.action}${step.action_params?.agent ? ` (${step.action_params.agent})` : ''}`
  ).join('\n');
}

/**
 * Get agent descriptions from registry
 */
function getAgentDescriptions(): string {
  const agents = AgentRegistry.getAllAgents();
  return agents.map(agent => {
    const prereqs = agent.prerequisites.length > 0 
      ? `Prerequisites: ${agent.prerequisites.join(', ')}` 
      : 'Prerequisites: None';
    const outputs = agent.outputs.length > 0 
      ? `Produces: ${agent.outputs.join(', ')}` 
      : 'Produces: Nothing';
    const deterministic = agent.is_deterministic ? ' (deterministic workflow)' : '';
    
    return `
- ${agent.agent_name}${deterministic}
  ${agent.description}
  ${prereqs}
  ${outputs}`;
  }).join('\n');
}

// ============================================================================
// Action Execution
// ============================================================================

/**
 * Execute reasoning action
 */
async function executeReasoningAction(
  reasoning: Reasoning,
  state: MultiAgentState,
  step: ReasoningStep
): Promise<Partial<MultiAgentState>> {
  
  switch (reasoning.action) {
    case 'call_agent':
      return handleCallAgent(reasoning, state, step);
      
    case 'validate':
      return handleValidate(reasoning, state, step);
      
    case 'recover':
      return handleRecover(reasoning, state, step);
      
    case 'clarify':
      return handleClarify(reasoning, state, step);
      
    case 'finalize':
      return handleFinalize(reasoning, state, step);
      
    default:
      console.error(`‚ùå [AGENTIC-SUPERVISOR] Unknown action: ${reasoning.action}`);
      return handleFinalize(reasoning, state, step);
  }
}

/**
 * Handle call_agent action
 */
function handleCallAgent(
  reasoning: Reasoning,
  state: MultiAgentState,
  step: ReasoningStep
): Partial<MultiAgentState> {
  const agentName = reasoning.params?.agent;
  
  if (!agentName) {
    console.error('‚ùå [AGENTIC-SUPERVISOR] No agent specified in call_agent action');
    return {
      next_agent: 'finalize',
      current_thought: 'No agent specified, finalizing',
      reasoning_history: [step],
    };
  }
  
  // Validate agent exists
  const validAgents = ['route_agent', 'compliance_agent', 'weather_agent', 'bunker_agent'];
  if (!validAgents.includes(agentName)) {
    console.error(`‚ùå [AGENTIC-SUPERVISOR] Invalid agent: ${agentName}`);
    return {
      next_agent: 'finalize',
      current_thought: `Invalid agent ${agentName}, finalizing`,
      reasoning_history: [step],
    };
  }
  
  console.log(`üéØ [AGENTIC-SUPERVISOR] Routing to: ${agentName}`);
  
  // Update step with observation
  step.observation = `Routing to ${agentName}`;
  
  return {
    next_agent: agentName,
    current_thought: reasoning.thought,
    reasoning_history: [step],
    needs_clarification: false,
  };
}

/**
 * Handle validate action
 */
function handleValidate(
  reasoning: Reasoning,
  state: MultiAgentState,
  step: ReasoningStep
): Partial<MultiAgentState> {
  console.log('‚úì [AGENTIC-SUPERVISOR] Validating prerequisites');
  
  step.observation = 'Validation complete, continuing reasoning';
  
  // Validation is internal - stay in supervisor for next reasoning step
  return {
    current_thought: reasoning.thought,
    reasoning_history: [step],
    next_agent: 'supervisor',
  };
}

/**
 * Handle recover action
 */
function handleRecover(
  reasoning: Reasoning,
  state: MultiAgentState,
  step: ReasoningStep
): Partial<MultiAgentState> {
  console.log('üîÑ [AGENTIC-SUPERVISOR] Attempting error recovery');
  
  const recoveryAction = reasoning.params?.recovery_action;
  const targetAgent = reasoning.params?.agent as string | undefined;
  
  if (recoveryAction === 'retry_agent' && targetAgent) {
    console.log(`üîÑ [AGENTIC-SUPERVISOR] Retrying ${targetAgent}`);
    step.observation = `Retrying ${targetAgent}`;
    
    // Clear agent's failed status to allow retry
    const newAgentStatus = { ...state.agent_status };
    delete newAgentStatus[targetAgent];
    
    return {
      next_agent: targetAgent,
      current_thought: reasoning.thought,
      reasoning_history: [step],
      recovery_attempts: 1,
      agent_status: newAgentStatus,
    };
  }
  
  if (recoveryAction === 'skip_agent') {
    console.log(`‚è≠Ô∏è [AGENTIC-SUPERVISOR] Skipping failed agent, continuing`);
    step.observation = `Skipping ${targetAgent || 'failed agent'}, continuing with available data`;
    
    // Mark agent as skipped
    const newAgentStatus = { ...state.agent_status };
    if (targetAgent) {
      newAgentStatus[targetAgent] = 'skipped';
    }
    
    return {
      next_agent: 'supervisor',
      current_thought: reasoning.thought,
      reasoning_history: [step],
      agent_status: newAgentStatus,
    };
  }
  
  if (recoveryAction === 'ask_user') {
    console.log('‚ùì [AGENTIC-SUPERVISOR] Asking user for help');
    step.observation = 'Need user clarification to proceed';
    
    return {
      needs_clarification: true,
      clarification_question: reasoning.params?.question || 'I encountered an issue. Could you provide more details?',
      current_thought: reasoning.thought,
      reasoning_history: [step],
      next_agent: 'finalize',
    };
  }
  
  // Unknown recovery action - finalize
  console.warn(`‚ö†Ô∏è [AGENTIC-SUPERVISOR] Unknown recovery action: ${recoveryAction}`);
  return handleFinalize(reasoning, state, step);
}

/**
 * Handle clarify action
 */
function handleClarify(
  reasoning: Reasoning,
  state: MultiAgentState,
  step: ReasoningStep
): Partial<MultiAgentState> {
  console.log('‚ùì [AGENTIC-SUPERVISOR] Need user clarification');
  
  const question = reasoning.params?.question || 'Could you please provide more details about your request?';
  step.observation = `Asking user: "${question}"`;
  
  return {
    needs_clarification: true,
    clarification_question: question,
    current_thought: reasoning.thought,
    reasoning_history: [step],
    next_agent: 'finalize',
  };
}

/**
 * Handle finalize action
 */
function handleFinalize(
  reasoning: Reasoning,
  state: MultiAgentState,
  step: ReasoningStep
): Partial<MultiAgentState> {
  console.log('‚úÖ [AGENTIC-SUPERVISOR] Finalizing with reasoning');
  
  step.observation = 'Proceeding to finalize';
  
  return {
    next_agent: 'finalize',
    current_thought: reasoning.thought,
    reasoning_history: [step],
    needs_clarification: false,
  };
}

// ============================================================================
// Exports
// ============================================================================

export { MAX_REASONING_STEPS, MAX_RECOVERY_ATTEMPTS };
